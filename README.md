# Gradio-Based CSV Question Answering and Visualization Application

## Overview
This project is a Gradio-based application that enables users to upload CSV files, ask questions about their contents, and receive answers generated by a local Large Language Model (LLM). The application also supports data visualization by plotting graphs directly within the Gradio interface.

## Solution Architecture
The application processes user queries using an LLM-powered agent. The LLM generates a structured response that includes:
- A **Python script** (`filter_script`) to compute the answer from the CSV data.
- A **graph specification** (`graph`) that determines whether visualization is required and, if so, specifies the graph type and labels.

This approach ensures dynamic and context-aware data processing while leveraging AI for both query resolution and visualization decision-making.

## Features
- **CSV File Handling**
  - Upload and validate CSV files
  - Handle parsing errors gracefully
- **Question Answering**
  - Accepts both textual and numerical queries
  - Uses a local LLM via the Ollama framework
  - Implements structured query processing using Pydantic AI
- **Graph Plotting & Visualization**
  - Generates visualizations based on CSV data when needed
  - The LLM determines if a graph is required and specifies its details
  - Display plots within the Gradio interface

## Tech Stack
- **Backend:** Python, Ollama, Pydantic AI, Pandas, Matplotlib
- **Frontend:** Gradio
- **LLM Model:** Llama 3.1 (configurable)

## Installation
### Prerequisites
Ensure you have Python installed (>=3.8) and Ollama set up for local LLM execution.

### Steps
1. Install Ollama:
   - **Linux/macOS:**
     ```sh
     curl -fsSL https://ollama.com/install.sh | sh
     ```
   - **Windows:**
     Download and install Ollama from [Ollama's official website](https://ollama.com/download) and follow the installation instructions.

2. Pull the Llama 3.1 model:
   ```sh
   ollama pull llama3.1
   ```
3. Clone the repository:
   ```sh
   git clone <repo-url>
   cd <repo-folder>
   ```
4. Install dependencies:
   ```sh
   pip install -r requirements.txt
   ```
5. Run the application:
   ```sh
   python main.py
   ```

## Configuration
Modify `config.yml` to adjust the LLM settings:
```yaml
Agent:
  model_name: "llama3.1"
  base_url: "http://localhost:11434/v1"
```

## Usage
1. Upload a CSV file through the Gradio interface.
2. Enter a question related to the dataset (e.g., "What is the average price?").
3. The LLM generates a Python script to compute the answer from the CSV.
4. The LLM also determines if a graph is required and specifies its type.
5. View the response and visualization (if applicable) directly in the Gradio UI.

## Testing
Run tests using:
```sh
pytest test/
```

## License
This project is open-source and available under the [MIT License](LICENSE).